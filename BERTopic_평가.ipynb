{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a79225-9879-47bf-a99f-710576a6053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hyukj'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b556874d-f71e-49fd-91c8-9f5c44c41c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pmid</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37196221</td>\n",
       "      <td>Messenger RNA (mRNA) has received great attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37150326</td>\n",
       "      <td>Lipid nanoparticles (LNPs) have revolutionized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>37741463</td>\n",
       "      <td>RNA therapies have recently taken a giant leap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>37162501</td>\n",
       "      <td>Lipid nanoparticles (LNPs) have been recognize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36719091</td>\n",
       "      <td>Based on the clinical success of an in vitro t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      pmid                                           abstract\n",
       "0           0  37196221  Messenger RNA (mRNA) has received great attent...\n",
       "1           1  37150326  Lipid nanoparticles (LNPs) have revolutionized...\n",
       "2           2  37741463  RNA therapies have recently taken a giant leap...\n",
       "3           3  37162501  Lipid nanoparticles (LNPs) have been recognize...\n",
       "4           4  36719091  Based on the clinical success of an in vitro t..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Pubmed_2021_2023.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f91203d-f21e-424a-8b2e-78cb0af78867",
   "metadata": {},
   "outputs": [],
   "source": [
    "docc=df[\"abstract\"].astype(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5ffefa6-46fa-4abc-9daa-fcf673d0721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "my_stop_words = [\n",
    "    \"to\",\"and\",\"liposomes\",\"of\",\"was\",\"lipid\",\"is\",\"be\",\"publication\",\"publishers\",\n",
    "    \"bentham\",\"copyright\",\"doi\",\"drug\",\"we\",\"delivery\",\"as\",\"cells\",\"nanoparticles\",\n",
    "    \"article\",\"journal\",\"for\",\"are\",\"by\",\"can\",\"retracts\",\"submitting\",\"authors\",\"manuscripts\",\n",
    "    \"editorial\",\"plagiarism\",\"permission\",\"published\",\"disclaimer\",\"legal\",\"forbidden\",\"corrects\",\n",
    "    \"apologizes\",\"inconvenience\",\"withdrawn\",\"illustration\",\"science\",\"policy\",\"table\",\n",
    "    \"submitted\",\"have\",\"cell\",\"if\",\"readers\",\"httpsbenthamsciencecomeditorialpoliciesmainphp\",\"withdrawal\",\n",
    "    \"yechezkel\",\"barenholzs\",\"using\",\"results\",\"elsewhere\",\"strictly\",\"study\",\"treatment\",\"on\"\n",
    "]\n",
    "\n",
    "# 위 규칙과 똑같은 CountVectorizer를 만듭니다 (학습 X, 도구 생성 O)\n",
    "vectorizer = CountVectorizer(stop_words=my_stop_words)\n",
    "\n",
    "# 이 vectorizer에서 '문서를 쪼개고 불용어를 버리는 기능(analyzer)'만 뽑아냅니다.\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# 2. 문서 토큰화 수행\n",
    "# -----------------------------------------------------------------------\n",
    "# 원본 문서를 analyzer에 통과시켜 토큰 리스트로 변환합니다.\n",
    "# 이제 'drug', 'delivery' 같은 단어는 리스트에서 사라집니다.\n",
    "tokenized_docs = [analyzer(doc) for doc in docc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2482c0c-3bb3-4414-997e-f2c58a5c9a63",
   "metadata": {},
   "source": [
    "### 아래는 간단한 토큰화 예시 코드(BERTopic의 재현을 위해 위 방식 사용했음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64cd2cb0-9263-4ce0-a356-1c2cb6e1b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 토큰화 완료: 총 13100개\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tokenized_docs = []\n",
    "for doc in docc:\n",
    "    # 1) 소문자 변환\n",
    "    # 2) 길이가 2 이상인 영문 단어만 추출 (특수문자, 숫자 제거)\n",
    "    tokens = re.findall(r'\\b[a-z]{2,}\\b', doc.lower())\n",
    "    tokenized_docs.append(tokens)\n",
    "\n",
    "# 결과 예시: \"This is a study.\" -> ['this', 'is', 'study']\n",
    "print(f\"문서 토큰화 완료: 총 {len(tokenized_docs)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a708db11-0716-4115-a395-36c2711037ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1 = ['cancer', 'tumor', 'potential', 'membrane', 'release']\n",
    "topic_2 = ['amphotericin', 'mucormycosis', 'fungal', 'antifungal', 'infections']\n",
    "topic_3 = ['chemotherapy', 'pld', 'pfs', 'doxorubicin', 'naliri']\n",
    "topic_4 = ['bupivacaine', 'opiod', 'postoperative', 'block', 'analgesia']\n",
    "topic_5 = ['ocular', 'retinal', 'corneal', 'glaucoma', 'intraocular']\n",
    "topic_6 = ['leishmaniasis', 'leishmania', 'amphotericin', 'cutaneous', 'diagnosis']\n",
    "\n",
    "topics = [topic_1, topic_2, topic_3,topic_4, topic_5, topic_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c51fe8-6233-4ffe-acd8-a1ed239b0664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 평가 결과 =====\n",
      "평가 토픽 개수: 6\n",
      "NPMI Score   : 0.1944 (범위: -1 ~ 1, 높을수록 좋음)\n",
      "C_v Score    : 0.7984  (범위: 0 ~ 1, 높을수록 좋음)\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "# 3. Coherence / NPMI 점수 계산\n",
    "# -------------------------------------------------------------\n",
    "# 사전(Dictionary) 생성\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "\n",
    "# (1) NPMI 점수 계산 (엄격한 기준, 추천)\n",
    "coherence_model_npmi = CoherenceModel(topics=topics, \n",
    "                                      texts=tokenized_docs, \n",
    "                                      dictionary=dictionary, \n",
    "                                      coherence='c_npmi')\n",
    "npmi_score = coherence_model_npmi.get_coherence()\n",
    "\n",
    "# (2) C_v 점수 계산 (보편적 기준)\n",
    "coherence_model_cv = CoherenceModel(topics=topics, \n",
    "                                    texts=tokenized_docs, \n",
    "                                    dictionary=dictionary, \n",
    "                                    coherence='c_v')\n",
    "cv_score = coherence_model_cv.get_coherence()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. 결과 출력\n",
    "# -------------------------------------------------------------\n",
    "print(f\"\\n===== 평가 결과 =====\")\n",
    "print(f\"평가 토픽 개수: {len(topics)}\")\n",
    "print(f\"NPMI Score   : {npmi_score:.4f} (범위: -1 ~ 1, 높을수록 좋음)\")\n",
    "print(f\"C_v Score    : {cv_score:.4f}  (범위: 0 ~ 1, 높을수록 좋음)\")\n",
    "print(f\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5bc89-95e6-433a-bbc8-8f3038438aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
